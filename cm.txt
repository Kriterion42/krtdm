ISP ens33: DHCP

ens34: 172.16.4.1 /28

ens35: 172.16.5.1 /28

HQ-RTR ens33: 172.16.4.2/28

ens34.vlan100: 

192.168.100.1/26

ens34.vlan200: 

192.168.200.1/28

ens34.vlan999: 

192.168.99.1/29

ens33:172.16.4.1

BR-RTR ens33: 172.16.5.2/28

ens34: 172.30.100.1/27

ens:33.172.16.5.1

HQ-SRV ens33.vlan100: 

192.168.100.10/26

ens33:192.168.100.1

BR-SRV ens33: 172.30.100.10/27 ens33:172.30.100.1

HQ-CLI ens33.vlan200: DHCP DHCP
ISP  
ens34: 172.16.4.1 /28 
ens35: 172.16.5.1 /28 
-----HQ-RTR 
  ens33: 172.16.4.2/28
172.16.4.1
10.39.0.1 
  ens34.vlan100: 
192.168.100.1/26
  ens34.vlan200: 
192.168.200.1/28 
  ens34.vlan999: 
192.168.99.1/29 
-----BR-RTR 
  ens33:172.16.5.2/28
172.16.5.1
10.39.0.1
  ens34: 172.30.100.1/27 
------HQ-SRV  
  ens33.vlan100: 192.168.100.10/26
192.168.100.1
10.39.0.1 
------BR-SRV 
ens33: 172.30.100.10/27 
172.30.100.1
10.39.0.1
-----HQ-CLI 
ens33.vlan200

1.1
hostnamectl hostname host-name.au-team.irpo, где host-name имя вашего устройства, например (hq-srv, br-rtr, isp).
− nmtui > Изменить подключение > Выбираем нужный интерфейс > Стрелочка вправо > Изменить > Конфигурация IPv4: Изменить с Автоматически на вручную и нажать > Показать > Адреса > Добавить, после чего задаём IP-адрес и при необходимости шлюз и серверы DNS, после чего сохраняем изменения с помощью ОК.
На этом пункте настраиваем все интерфейсы на устройствах – ISP, BR-RTR, BR-SRV. На HQ-RTR настраиваем интерфейс в сторону ISP. Интерфейсы на устройствах HQ-RTR, HQ-SRV и HQ-CLI находящиеся в локальной сети HQ будут настраиваться в пункте №4.
Для применения изменений выходим в командную строку и прописываем команду:
nmcli connection up INTERFACE, где INTERFACE – название вашего интерфейса, настройки которого необходимо обновить (например, ens33).
На маршрутизаторах (ISP/BR-RTR/HQ-RTR) включаем параметр, отвечающий за пересылку пакетов:
echo “net.ipv4.ip_forward=1” >> /etc/sysctl.conf
sysctl -p

1.2
НА ISP
dnf install iptables-services -y
systemctl enable --now iptables
iptables -F
iptables -A FORWARD -s 172.16.0.0/16 -j ACCEPT
iptables -A FORWARD -d 172.16.0.0/16 -j ACCEPT
iptables -t nat -A POSTROUTING -o ens33 -s 172.16.0.0/16 -j MASQUERADE
systemctl stop firewalld
systemctl disable firewalld
iptables-save > /etc/sysconfig/iptables
ПРОВЕРЯЕМ ПИНГИ НА 8.8.8.8 С HQ-RTR и BR-RTR

1.3
useradd -m -U -s /bin/bash -u 1010 sshuser
passwd sshuser
P@ssw0rd
P@ssw0rd
echo “sshuser ALL=(ALL) NOPASSWD: ALL” >> /etc/sudoers
useradd -m -U -s /bin/bash net_admin
passwd net_admin
P@$$w0rd
P@$$w0rd
echo “net_admin ALL=(ALL) NOPASSWD: ALL” >> /etc/sudoers

1.4
nmtui > Изменить подключение > Добавить > VLAN и настраиваем VLAN. Данный шаг выполняем на HQ-RTR – ens34, HQ-SRV – ens33, HQ-CLI – ens33.
(Шлюз и Серверы DNS для HQ-CLI и HQ-SRV)

1.5
Создаём баннер
echo “Authorized access only” > /etc/ssh/banner.txt
Настраиваем SSH
nano /etc/ssh/sshd_config
Port 2024
AllowUsers sshuser
MaxAuthTries 2
Banner /etc/ssh/banner.txt
Разрешаем подключение по порту 2024
semanage port -m -t ssh_port_t -p tcp 2024
(либо выключаем SELinux и перезапускаем сервер)
Перезапускаем ssh
systemctl restart sshd
Далее с HQ-RTR и BR-RTR проверяем доступ до соответствующих серверов в своей локальной сети:
ssh -l sshuser 172.30.100.10 -p 2024
ssh -l sshuser 192.168.100.10 -p 2024

1.6
Заходим в nmtui
Стрелочка вправо – добавить
Выбираем IP-Туннель
Конфигурируем дальше по скринам, не забыв изменить режим на GRE
HQ-RTR
ПОСЛЕ ЭТОГО НА ОБОИХ РОУТЕРАХ ПИШЕМ:
nmcli connection modify tun0 ip-tunnel.ttl 64
И перезапускаем tunnel через nmtui (выключаем и включаем интерфейс)
Проверяем пинги с двух роутеров на 10.10.10.1 и 10.10.10.2

1.7
HQ-RTR И BR-RTR
dnf install frr
systemctl enable --now frr
nano /etc/frr/daemons
заменить no на yes в ospfd=yes
systemctl restart frr
vtysh
conf t
router ospf
Команды для HQ-RTR
network 192.168.100.0/26 area 0
network 192.168.200.0/28 area 0
network 192.168.99.0/29 area 0
network 10.10.10.0/30 area 0
ospf router-id 172.16.4.2
passive-interface ens33
passive-interface ens34
passive-interface ens35
Команды для BR-RTR
network 172.30.100.0/27 area 0
network 10.10.10.0/30 area 0
ospf router-id 172.16.5.2
passive-interface ens33
passive-interface ens34
area 0 authentication
exit
interface tun0
ip ospf authentication
ip ospf authentication-key P@ssw0rd
do wr
exit
exit
exit

1.8
НА HQ-RTR И BR-RTR:
systemctl --now enable firewalld
firewall-cmd --set-default-zone=trusted
firewall-cmd --zone=trusted --add-masquerade --permanent
systemctl restart firewalld

1.9
dnf install dhcp-server
nano /etc/dhcp/dhcpd.conf
Пишем это в файле:
subnet 192.168.200.0 netmask 255.255.255.240 {
range 192.168.200.2 192.168.200.14;
option routers 192.168.200.1;
option broadcast-address 192.168.200.15;
option domain-name-servers 192.168.100.10;
option domain-name “au-team.irpo”;
}
systemctl enable --now dhcpd
dhcpd
Получаем адрес на HQ-CLI путём отключения и включения интерфейса ens33.vlan200.
ПРОВЕРЯЕМ НА HQ-RTR, ЧТО ЕСТЬ ЗАПИСЬ В ФАЙЛЕ, УКАЗЫВАЮЩАЯ НА ПОЛУЧЕНИЕ АДРЕС КЛИЕНТОМ:
cat /var/lib/dhcpd/dhcpd.leases

1.10
dnf install bind
nano /etc/named.conf
listen-on port 53 {any;};
allow-query {any:};
forwarders {10.39.0.1};
в конце
zone "au-team.irpo" IN {type master; file"/opt/dns/au-team.irpo";};
zone "100.168.192.in-addr.arpa" IN {type master; file"/opt/dns/100.168.192.in-addr.arpa";};
zone "200.168.192.in-addr.arpa" IN {type master; file"/opt/dns/200.168.192.in-addr.arpa";};
include "/etc/namde.rfc1912.zones";
include "etc/named.root.key"
mkdir /opt/dns
cd /opt/dns
cp /var/named/named.empty au-team.irpo
nano au-team.irpo
au-team.irpo. IN SOA au-team.irpo au-team.irpo
NS hq-srv.au-team.irpo.
hq-rtr A 192.168.100.1
hq-rtr A 192.168.200.1
br-rtr A 172.30.100.1
hq-srv A 192.168.100.10
hq-cli A 192.168.200.2
br-srv A 172.30.100.10
wiki CNAME hq-rtr.au-team.irpo.
moodle CNAME hq-rtr.au-team.irpo.
cp /var/named/named.empty 100.168.192.in-addr.arpa
nano 100.168.192.in-addr.arpa
au-team.irpo. IN SOA au-team.irpo au-team.irpo
NS hq-srv.au-team.irpo.
1 PTR hq-rtr
10 PTR hq-srv
cp /var/named/named.empty 200.168.192.in-addr.arpa
nano 200.168.192.in-addr.arpa
au-team.irpo. IN SOA au-team.irpo au-team.irpo
NS hq-srv.au-team.irpo.
1 PTR hq-rtr
2 PTR hq-cli
chmod -R 777 /opt/dns
ПРОВЕРЯЕМ КОНФИГУРАЦИЮ И ИСПРАВЛЯЕМ ОШИБКИ ЕСЛИ ЕСТЬ
named-checkconf -z
systemctl restart named
Далее заходим в nmtui и меняем ДНС сервер с 8.8.8.8 (10.39.0.1) на 192.168.100.10. Так же указываем домен поиска au-team.irpo.
После этого в nmtui переходим на вкладку «Активировать подключение». Выключаем и включаем интерфейс, на который ставили ДНС
НА HQ-CLI И ПРОВЕРЯЕМ РАБОТОСПОБНОСТЬ
ping br-rtr
ping br-srv
ping hq-rtr
ping hq-srv
ping ya.ru

1.11
timedatectl set-timezone Europe/Moscow
timedatectl
###

2.1
Устанавливаем Samba на BR-SRV:
dnf install samba* krb5*
mv /etc/samba/smb.conf /etc/samba/smb.conf.bak mv /etc/krb5.conf /etc/krb5.conf.bak
nano /etc/krb5.conf.d/crypto-policies
Изменяем файл следующим образом:
default_tgs/tkt
Для этого ставим курсор на существующую строчку permitted_enctypes, нажимаем CTRL+K и три раза CTRL+U. После этого изменяем начало первых двух строчек.
samba-tool domain provision --use-rfc2307 --interactive
Далее на моменте DNS backend пишем “NONE”. Затем указываем пароль администратора: P@ssw0rd
cp /var/lib/samba/private/krb5.conf /etc/krb5.conf
nano /etc/krb5.conf
В realms добавляем kdc
systemctl enable --now samba
reboot
kinit administrator@AU-TEAM.IRPO
Переходим на HQ-CLI, переходим в root и пишем: echo “172.30.100.10 au-team.irpo” >> /etc/hosts
realm join -U -v Administrator@AU-TEAM.IRPO
В конце добавления должна появиться надпись “Successfully enrolled machine in realm”
Возвращаемся на BR-SRV. Далее создаем группу hq и добавляем в нее всех созданных пользователей.
samba-tool group add hq
for i in {1..5}; do samba-tool user add user$i.hq P@ssw0rd; samba-tool group addmembers hq user$i.hq; done
Проверяем:
samba-tool group listmembers hq
(smb-tool gr add hq
smb-tool usr add us1.hq P@ss
smb-tool gr addmmb hq us1.hq)
Переходим на HQ-CLI nano /etc/sssd/sssd.conf
Меняем значение ad_server на br-srv.au-team.irpo
systemctl restart sssd nano /etc/krb5.conf
Приводим файл к следующему виду:
default_realm = AU-TEAM.IRPO
udp_preference_limit = 0
[realms]
AU-TEAM.IRPO = {
            kdc = br-srv.au-team.irpo
            admin_server = br-srv.au-team.irpo
}
[domain_realm]
.au-team.irpo = AU-TEAM.IRPO
au-team.irpo = AU-TEAM.IRPO
Далее переходим в «Настройки» - «Сетевые учетные записи».
Выбираем Kerberos, вводим administrator@AU-TEAM.IRPO и P@ssw0rd
sss_cache -E Перезапускаем HQ-CLI Проверяем:
id user1.hq@AU-TEAM.IRPO su - user1.hq@AU-TEAM.IRPO
Выходим из пользователя и заходим в настройку root прав
visudo
Пишем в файл следующую строку:
%hq@au-team.irpo ALL=(ALL) /bin/cat, /bin/grep, /bin/id
Проверяем:
su – user1.hq@au-team.irpo

2.2
VMWare нажимаем сверху ПКМ на HQ-SRV, выбираем последний пункт Settings и нажимаем кнопку add. Выбираем Hard Drive.
Тип диска - SATA, “Create a new virtual disk”, Maximum disk size - 1. В имени диска меняем цифру на конце на 10, 11, 12 соответственно для трех дисков. Нажимаем Finish.
Проверяем наличие дисков командой. Должны быть sdb, sdc, sdd. lsblk
fdisk /dev/sdb g
n
Жмем Enter 3 раза
W
Далее проделываем тоже самое для дисков sdc и sdd.
Должно получится таким образом:
mdadm --create --verbose /dev/md0 -l 5 -n 3 /dev/sd[b-d]1
Далее проверяем, в типе должно быть написано RAID5
mdadm --detail --scan --verbose >> /etc/mdadm.conf mkfs.ext4 /dev/md0
mkdir /raid5 nano /etc/fstab
В конец добавляем следующую строчку:
/dev/md0 /raid5 ext4 defaults 0 0
systemctl daemon-reload mount -a
df -h
Должна быть строчка с примонтированной директорией /raid5
dnf install nfs4-acl-tools mkdir /raid5/nfs
chown nobody:nobody /raid5/nfs
chmod 777 /raid5/nfs nano /etc/exports
Добавляем в него следующую строчку:
/raid5/nfs 192.168.200.0/28 (rw) exportfs -a
systemctl enable --now nfs-server
Переходим на HQ-CLI:
mkdir /mnt/nfs nano /etc/fstab
Добавляем следующую строчку:
192.168.100.10:/raid5/nfs /mnt/nfs nfs auto 0 0 mount -a
Проверяем с помощью команды df -h, должна появиться запись.

2.3
На HQ-RTR
nano /etc/chrony.conf
server 127.0.0.1 iburst prefer
local stratum 5
allow 0/0
hwtimestamp *_
systemctl restart chronyd
Проверяем: chronyc sources
На HQ-SRV, HQ-CLI, BR-RTR, BR-SRV:
nano /etc/chrony.conf
Комментируем все сервера и добавляем созданный:
server 192.168.100.1 iburst prefer
Далее перезапускаем сервис:
systemctl restart chronyd
Проверяем:
chronyc sources

2.4
nano /etc/ansible/demo.yml
VMs:
hosts:
HQ-SRV:
ansible_host: 192.168.100.10
ansible_user: sshuser
ansible_port: 2024
HQ-CLI:
a_h:192.168.200.2
a_u:username
a_p:22
HQ-RTR
a_h:192.168.100.1
a_u:net_admin
a_p:22
BR-RTR
a_h:172.30.100.1
a_u:netadmin
a_p:22
ssh-keygen -t rsa
Жмем Enter всегда до конца выполнения команды
Далее копируем ключи. На вопрос с сохранием отпечатка пишем yes,
пароль от sshuser - P@ssw0rd, от username - P@ssw0rd, от net_admin -
P@$$w0rd
ssh-copy-id -p 2024 sshuser@192.168.100.10 ssh-copy-id username@192.168.200.2
ssh-copy-id net_admin@192.168.100.1 ssh-copy-id net_admin@172.30.100.01
Составляем конфигурационный файл: nano /etc/ansible/ansible.cfg
defaults]
inuentory = ./demo.yml
ask_pass = False
host_key_cheking = False
interpreter_python = /usr/bin/python
Проверяем настройку:
ansible -m ping all

2.5
dnf install docker-ce docker-compose -y
cd /home/username
systemctl enable docker --now
Находим там раздел «Adding a Database Server»
nano wiki.yml
И копируем в него содержимое этого раздела. Вносим изменения в порт, образ контейнера с БД, пароль пользователя к БД и пусть хранения volume. Приводим файл к следующему виду:
ports: - 8080:80
container_name: mariadb
image: mariadb
MYSQL_PASSWORD: WikiP@ssw0rd
volumes: - dbvolume: /var/lib/maridb
перед services убрать пробел
Строчка с комментарием должна быть в таком виде, она нужна будет позже.
docker volume create dbvolume docker-compose -f wiki.yml up -d Проверяем:
docker ps -a
Переходим на клиента, заходим в браузер и вводим в адресную строку 172.30.100.10:8080. Далее нажимаем “set up the wiki”. Жмем далее до момента ввода данных о БД. Заполняет данные о mariadb:
Затем переходим к установке mediawiki:
После завершения установка mediawiki должен быть скачан файл с настройками - LocalSettings.php. Его необходимо передать на BR-SRV.
scp -P 2024 /home/username/Загрузки/LocalSettings.php sshuser@172.30.100.10:/tmp
После этого переходим на BR-SRV:
mv /tmp/LocalSettings.php /home/username nano wiki.yaml
Убираем комментарий со строчки.
Перезапускаем докер
docker-compose -f wiki.yml stop docker-compose -f wiki.yml up -d
Возвращаемся на клиента, переходим по адресу 172.30.100.10:8080 и проверяем настроенное приложение. Входим в созданную учетную запись

2.6
На BR-RTR пробрасываем его 80 в 8080 BR-SRV и пробрасываем его 2024 в 2024 BR-SRV:
iptables -t nat -A PREROUTING -p tcp -m tcp -d 172.16.5.2/24 --dport 80 -j DNAT --to-destination 172.30.100.10:8080
iptables -t nat -A PREROUTING -p tcp -m tcp -d 172.16.5.2/24 --dport 2024 -j DNAT --to-destination 172.30.100.10:2024
iptables-save > /etc/sysconfig/iptables
После этого с клиента переходим по адресу 172.16.5.1, нас должно перевести на страницу с MediaWiki.
Проверяем порт 2024 по SSH:
ssh –p 2024 sshuser@172.16.5.10
Подключить нас должно к BR-SRV
На HQ-RTR пробрасываем его 2024 в 2024 HQ-SRV:
iptables -t nat -A PREROUTING -p tcp -m tcp -d 172.16.4.2/28 --dport 2024 -j DNAT --to-destination 192.168.100.10:2024
iptables-save > /etc/sysconfig/iptables
Проверяем порт 2024 по SSH: ssh –p 2024 sshuser@172.16.4.10
Подключить нас должно к HQ-SRV

2.7
dnf install httpd mariadb mariadb-server php php-mysqlnd php-pdo php- gd php-mbstring php-zip php-intl php-soap
nano /etc/php.ini
На следующей строчке после [PHP] пишем
max_input_vars=6000
systemctl enable --now httpd php-fpm mariadb systemctl restart httpd php-fpm mariadb mysql_secure_installation
Пишем пароль для рута - P@ssw0rd. На все остальные вопросы отвечаем Yes.
mysql -u root -p
CREATE DATABASE moodledb DEFAULT CHARACTER SET utf8;
CREATE USER moodle@localhost IDENTIFIED BY ‘P@ssw0rd’;
GRANT ALL ON moodledb.* TO 'moodle'@'localhost'; flush privileges;
quit;
systemctl restart mariadb
Далее переходим на сайт moodle.org, в раздел Downloads и скачиваем
После этого переходим в загрузки, ПКМ по скачанному архиву и
«Копировать адрес ссылки».
wget https://packaging.moodle.org/stable405/moodle-latest-405.tgz tar -xzf moodle-latest-4.0.5.tgz
mv moodle/* /var/www/html
chown -R apache:apache /var/www/html
chmod -R 0777 /var/www/html mkdir /var/moodledata
chown -R apache:apache /var/moodledata chmod -R 0777 /var/moodledata systemctl restart httpd
После этого переходим на клиента и вводим в адресной 192.168.100.1 и продолжаем установку.
Каталог данный указываем /var/moodledata
База данных - MariaDB
Указываем данные для подключения к базе данных
Принимаем лицензионное соглашение, смотрим что минимальные требования к установке выполнены и устанавливаем.
После установки нажимаем продолжить внизу страницы. далее заполняем основные параметры учетной записи.
После этого заполняем параметры главное страницы. Указываем номер нашего рабочего места (на скрине указал IP адрес стенда, на котором это выполнялось)
После этого сохраняем изменения. Указываем адрес поддержки - demo@demo.demo. Установка завершена.

2.8
dnf install nginx
systemctl enable --now nginx nano /etc/nginx/nginx.conf
В файле комментируем созданный по умолчанию сервер и добавляем в него 2 других, как показано на рисунуке:
server { listen80; server_name moodle/wiki.au-team.irpo; location / { proxy_pass http://192.168.100.10:80/172.30.100.10:8080}}
systemctl restart nginx Идем на клиента и в адресной строке пишем http://wiki.au-team.irpo и
http://moodle.au-team.irpo. Нас должно перенаправлять на сайты.
